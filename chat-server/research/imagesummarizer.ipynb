{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# prepare image + question\n",
    "image_path = \"../data/images/\"\n",
    "images = [os.path.join(image_path, i) for i in os.listdir(image_path)]\n",
    "image = Image.open(images[0]).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch, auto_gptq\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "# from auto_gptq.modeling import BaseGPTQForCausalLM\n",
    "\n",
    "# auto_gptq.modeling._base.SUPPORTED_MODELS = [\"internlm\"]\n",
    "# torch.set_grad_enabled(False)\n",
    "\n",
    "# class InternLMXComposer2QForCausalLM(BaseGPTQForCausalLM):\n",
    "#     layers_block_name = \"model.layers\"\n",
    "#     outside_layer_modules = [\n",
    "#         'vit', 'vision_proj', 'model.tok_embeddings', 'model.norm', 'output',\n",
    "#     ]\n",
    "#     inside_layer_modules = [\n",
    "#         [\"attention.wqkv.linear\"],\n",
    "#         [\"attention.wo.linear\"],\n",
    "#         [\"feed_forward.w1.linear\", \"feed_forward.w3.linear\"],\n",
    "#         [\"feed_forward.w2.linear\"],\n",
    "#     ]\n",
    "\n",
    "# # init model and tokenizer\n",
    "# model = InternLMXComposer2QForCausalLM.from_quantized(\n",
    "#   'internlm/internlm-xcomposer2-vl-7b-4bit', trust_remote_code=True, device=\"cuda:0\").eval()\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\n",
    "#   'internlm/internlm-xcomposer2-vl-7b-4bit', trust_remote_code=True)\n",
    "\n",
    "#The image features a quote by Oscar Wilde, \"Live life with no excuses, travel with no regrets.\"\n",
    "#The quote is displayed in white text against a dark background. In the foreground, there are two silhouettes of people standing on a hill at sunset. \n",
    "#They appear to be hiking or climbing, as one of them is holding a walking stick. \n",
    "#The sky behind them is painted with hues of orange and purple, creating a beautiful contrast with the dark figures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Findings\n",
    "# 1. internlm/internlm-xcomposer2-vl-7b-4bit: Model is quite good but too slow for real-time applications (3-4 mins per image)\n",
    "# 2. llava-v1.6-mistral-7b-hf (4-bit) : good results, faster (1-2 mins per image) but not too fast\n",
    "# 3. google/pix2struct-ai2d-base (quite small):\n",
    "# 4. vikhyatk/moondream2: reasonably good and fast (30-40 seconds per image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image presents a diagram of a cloud computing system, divided into three distinct layers. The topmost layer is a Nodejs Web Application, the middle layer is a Nodejs ElasticCache, and the bottom layer is a Nodejs Redshift. Each layer is represented by a blue box, and arrows are drawn to indicate the flow of data between the layers. The diagram is set against a white background, and the text \"First access to non-cached queries\" is written at the bottom.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from PIL import Image\n",
    "\n",
    "# model_id = \"vikhyatk/moondream2\"\n",
    "# revision = \"2024-04-02\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id, trust_remote_code=True, revision=revision\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id, revision=revision)\n",
    "\n",
    "#image = Image.open(image)\n",
    "enc_image = model.encode_image(image)\n",
    "print(model.answer_question(enc_image, \"Describe this image.\", tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
